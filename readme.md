DÆ°á»›i Ä‘Ã¢y lÃ  README.md hoÃ n chá»‰nh Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t, bao gá»“m cáº£ hÃ¬nh áº£nh schema cá»§a source, schema cá»§a Data Warehouse vÃ  luá»“ng ETL. MÃ¬nh giáº£ Ä‘á»‹nh ráº±ng báº¡n Ä‘Ã£ lÆ°u cÃ¡c hÃ¬nh áº£nh vÃ o thÆ° má»¥c `docs/images/` vá»›i tÃªn file tÆ°Æ¡ng á»©ng. Báº¡n cÃ³ thá»ƒ Ä‘iá»u chá»‰nh Ä‘Æ°á»ng dáº«n náº¿u cáº§n:

---

```markdown
# ğŸ“„ Logistics Data Warehouse

## ğŸ“– Giá»›i thiá»‡u

Project Logistics Data Warehouse xÃ¢y dá»±ng má»™t há»‡ thá»‘ng ETL toÃ n diá»‡n nháº±m ingest, transform vÃ  lÆ°u trá»¯ dá»¯ liá»‡u phá»¥c vá»¥ phÃ¢n tÃ­ch vÃ  bÃ¡o cÃ¡o. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ¹ng má»™t nguá»“n dá»¯ liá»‡u tá»« **MySQL** (vá»›i schema nguá»“n) vÃ  cÃ¹ng má»™t **Data Warehouse Schema** lÃ m káº¿t quáº£ cuá»‘i cÃ¹ng, nhÆ°ng ETL Ä‘Æ°á»£c triá»ƒn khai theo hai hÆ°á»›ng khÃ¡c nhau:
- **ETL báº±ng dbt**: Sá»­ dá»¥ng dbt Ä‘á»ƒ thá»±c hiá»‡n transform dá»¯ liá»‡u.
- **ETL báº±ng Spark**: Sá»­ dá»¥ng Apache Spark Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c bÆ°á»›c lÃ m sáº¡ch, chuyá»ƒn Ä‘á»•i vÃ  load dá»¯ liá»‡u.

## ğŸ” Data Source & Final Data Warehouse Schema

### 1. MySQL Schema (Source)
- **Vai trÃ²**: ÄÃ¢y lÃ  nguá»“n dá»¯ liá»‡u gá»‘c cá»§a há»‡ thá»‘ng, chá»©a cÃ¡c báº£ng nhÆ°: **Users**, **Drivers**, **Orders**, **Shipments**, **Payments**, **Notifications**.
- **CÃ¡ch sá»­ dá»¥ng**: Dá»¯ liá»‡u tá»« MySQL Ä‘Æ°á»£c trÃ­ch xuáº¥t thÃ´ng qua Kafka Connect (sá»­ dá»¥ng Debezium MySQL Connector) vÃ  ingest vÃ o há»‡ thá»‘ng.

![Source Schema](source_schema.png)

### 2. Data Warehouse Schema (Final Result)
- **Vai trÃ²**: ÄÃ¢y lÃ  schema cuá»‘i cÃ¹ng cá»§a Data Warehouse, Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c transform vÃ  tÃ­ch há»£p tá»« nguá»“n.
- **ThÃ nh pháº§n**: Bao gá»“m cÃ¡c báº£ng dimension vÃ  fact (theo mÃ´ hÃ¬nh Kimball) Ä‘Æ°á»£c lÆ°u trá»¯ trong há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ­ch (ClickHouse hoáº·c Delta Table thÃ´ng qua Spark).

![Data Warehouse Schema](data_warehouse_schema.png)

## ğŸ”„ Kiáº¿n trÃºc há»‡ thá»‘ng

### Ingest & Processing
- **Nguá»“n dá»¯ liá»‡u**: MySQL (source schema).
- **ETL báº±ng Spark**:
  - **Raw Layer**: Dá»¯ liá»‡u Ä‘Æ°á»£c ingest tá»« Kafka báº±ng HDFS Sink Connector dÆ°á»›i dáº¡ng Avro, phÃ¢n vÃ¹ng theo ngÃ y/thÃ¡ng/nÄƒm.
  - **Enriched Layer**: Sá»­ dá»¥ng Apache Spark Ä‘á»ƒ lá»c, lÃ m sáº¡ch vÃ  chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u, lÆ°u dÆ°á»›i dáº¡ng Parquet.
  - **Curated Layer**: Spark tiáº¿p tá»¥c xá»­ lÃ½ Ä‘á»ƒ xÃ¢y dá»±ng Data Warehouse, lÆ°u dÆ°á»›i dáº¡ng Delta Table.
- **ETL báº±ng dbt**:
  - Sá»­ dá»¥ng dbt Ä‘á»ƒ thá»±c hiá»‡n transform dá»¯ liá»‡u tá»« cÃ¡c báº£ng nguá»“n, Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° Slowly Changing Dimension Type 2 (SCD Type 2) vÃ  Incremental Append, nháº±m xÃ¢y dá»±ng cÃ¡c báº£ng dimension vÃ  fact trong Data Warehouse Schema.

### Orchestration
- **Apache Airflow**: Äiá»u phá»‘i toÃ n bá»™ quy trÃ¬nh ETL, bao gá»“m viá»‡c cháº¡y cÃ¡c job Spark vÃ  cÃ¡c lá»‡nh dbt theo lá»‹ch trÃ¬nh.

### Analytical Storage
- **ClickHouse**: LÆ°u trá»¯ vÃ  truy váº¥n dá»¯ liá»‡u ingest tá»« ClickHouse Sink Connector, cÃ¹ng vá»›i cÃ¡c view há»— trá»£ bÃ¡o cÃ¡o Power BI.

![ETL Flow](etl_flow.svg)

## ğŸ“‚ Cáº¥u trÃºc dá»± Ã¡n

### 1. Airflow
- **Dockerfile**: Image Apache Airflow má»Ÿ rá»™ng cÃ i Spark, Java vÃ  cÃ¡c thÆ° viá»‡n bá»• sung.
- **dags/**: Chá»©a cÃ¡c DAG Ä‘iá»u phá»‘i cÃ´ng viá»‡c:
  - `spark_logistics_dag`: DAG cho cÃ¡c Spark Application (ETL báº±ng Spark).
  - (Náº¿u Ã¡p dá»¥ng) `dbt_logistics_dag`: DAG Ä‘iá»u phá»‘i cÃ¡c lá»‡nh dbt.
- **requirements.txt**: Danh sÃ¡ch cÃ¡c thÆ° viá»‡n Python cáº§n thiáº¿t.

### 2. ClickHouse
- **clickhouse-creating-tables/**: CÃ¡c file SQL táº¡o báº£ng trong ClickHouse Ä‘á»ƒ há»©ng dá»¯ liá»‡u tá»« ClickHouse Sink Connector.
- **creating-views/**: CÃ¡c file SQL táº¡o view cho cÃ¡c báº£ng dimension (vÃ­ dá»¥: `dim_date`, `dim_locations`) phá»¥c vá»¥ bÃ¡o cÃ¡o Power BI.

### 3. ETL theo Spark
- **Raw Layer**: Ingest dá»¯ liá»‡u tá»« Kafka vÃ o HDFS báº±ng HDFS Sink Connector (Avro, phÃ¢n vÃ¹ng theo thá»i gian).
- **Enriched Layer**: Sá»­ dá»¥ng Spark Ä‘á»ƒ lÃ m sáº¡ch vÃ  chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u, lÆ°u dÆ°á»›i dáº¡ng Parquet.
- **Curated Layer**: Sá»­ dá»¥ng Spark Ä‘á»ƒ tÃ­ch há»£p dá»¯ liá»‡u thÃ nh Data Warehouse, lÆ°u dÆ°á»›i dáº¡ng Delta Table.

### 4. ETL theo dbt
- **Staging Layer**: Chuáº©n hÃ³a dá»¯ liá»‡u tá»« MySQL.
- **Dimension Layer**: XÃ¢y dá»±ng cÃ¡c báº£ng dimension (vÃ­ dá»¥: `dim_users` vá»›i SCD Type 2, `dim_locations` vá»›i Append Strategy).
- **Fact Layer**: XÃ¢y dá»±ng cÃ¡c báº£ng fact phá»¥c vá»¥ phÃ¢n tÃ­ch.

### 5. MySQL Schema & Data Warehouse Schema
- **MySQL Schema (Source)**: Schema ban Ä‘áº§u chá»©a cÃ¡c báº£ng nguá»“n tá»« MySQL.
- **Data Warehouse Schema (Final Result)**: Schema sau khi tÃ­ch há»£p vÃ  transform, chá»©a cÃ¡c báº£ng dimension vÃ  fact phá»¥c vá»¥ bÃ¡o cÃ¡o.

## ğŸš€ HÆ°á»›ng dáº«n váº­n hÃ nh

### Airflow
1. **XÃ¢y dá»±ng Image Airflow**:  
   ```bash
   docker build -t my-airflow-image .
   ```
2. **CÃ i Ä‘áº·t cÃ¡c package Python**:
   ```bash
   pip install -r requirements.txt
   ```
3. **Khá»Ÿi Ä‘á»™ng Airflow**:  
   Äáº£m báº£o cÃ¡c DAG (nhÆ° `spark_logistics_dag`) Ä‘Æ°á»£c load vÃ  cháº¡y Ä‘Ãºng theo lá»‹ch trÃ¬nh.

### ClickHouse
1. **Káº¿t ná»‘i Ä‘áº¿n ClickHouse trÃªn local**:
   ```bash
   clickhouse-client --host localhost --port 8123 --user <username> --password <password>
   ```
2. **Táº¡o báº£ng vÃ  view**:
   - Cháº¡y cÃ¡c file SQL trong thÆ° má»¥c `clickhouse-creating-tables` Ä‘á»ƒ táº¡o cÃ¡c báº£ng cáº§n thiáº¿t.
   - Sau Ä‘Ã³, cháº¡y cÃ¡c file SQL trong thÆ° má»¥c `creating-views` Ä‘á»ƒ táº¡o view phá»¥c vá»¥ bÃ¡o cÃ¡o (Power BI).

### ETL báº±ng Spark
1. **Ingest dá»¯ liá»‡u (Raw Layer)**:  
   Cáº¥u hÃ¬nh HDFS Sink Connector Ä‘á»ƒ ingest dá»¯ liá»‡u tá»« Kafka vÃ o HDFS vá»›i Ä‘á»‹nh dáº¡ng Avro vÃ  phÃ¢n vÃ¹ng theo ngÃ y, thÃ¡ng, nÄƒm.
2. **Transform & Load**:
   - Cháº¡y Spark job Ä‘á»ƒ chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u tá»« Raw â†’ Enriched (Parquet).
   - Cháº¡y Spark job Ä‘á»ƒ táº¡o Data Warehouse tá»« Enriched (Delta Table).

### ETL báº±ng dbt
1. **CÃ i Ä‘áº·t packages dbt**:
   ```bash
   dbt deps
   ```
2. **Cháº¡y toÃ n bá»™ models**:
   ```bash
   dbt run
   ```
3. **Cháº¡y riÃªng models SCD Type 2 (vÃ­ dá»¥: dim_users)**:
   ```bash
   dbt run --select dim_users
   ```

## ğŸ“Œ Káº¿t luáº­n

Project Logistics Data Warehouse tÃ­ch há»£p cÃ¡c cÃ´ng nghá»‡ hiá»‡n Ä‘áº¡i Ä‘á»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng ETL toÃ n diá»‡n:
- **Source**: MySQL Schema, nÆ¡i dá»¯ liá»‡u gá»‘c Ä‘Æ°á»£c láº¥y tá»« há»‡ thá»‘ng MySQL.
- **ETL**: ÄÆ°á»£c thá»±c hiá»‡n qua hai hÆ°á»›ng Ä‘á»™c láº­p:
  - **Spark**: Xá»­ lÃ½ dá»¯ liá»‡u tá»« Raw (Avro) â†’ Enriched (Parquet) â†’ Curated (Delta Table).
  - **dbt**: Transform dá»¯ liá»‡u tá»« cÃ¡c báº£ng nguá»“n Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c model dimension vÃ  fact.
- **Final Result**: Data Warehouse Schema, nÆ¡i lÆ°u trá»¯ dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vÃ  tá»‘i Æ°u cho bÃ¡o cÃ¡o vÃ  phÃ¢n tÃ­ch.
- **Orchestration & Analytical Storage**: Apache Airflow Ä‘áº£m báº£o quy trÃ¬nh ETL tá»± Ä‘á»™ng vÃ  ClickHouse há»— trá»£ truy váº¥n dá»¯ liá»‡u hiá»‡u quáº£.
